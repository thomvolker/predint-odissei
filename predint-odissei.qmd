---
title: "Prediction intervals with missing data"
subtitle: "Department of Methodology and Statistics, Utrecht University"
author:
  - name: "Thom B. Volker"
  - name: "Florian D. van Leeuwen"
  - name: "Stef van Buuren"
format:
  revealjs:
    theme: [C:/Users/5868777/surfdrive/Documents/slides-theme/website-theme/website-theme.scss]
    logo: "universiteit-utrecht-logo.png"
    incremental: false
bibliography: pred_int.bib
---

## Uncertainty quantification

Proper uncertainty quantification is essential in prediction settings


:::: {.columns}
::: {.column width="55%"}
- Expected grade
- Election polling
- Package delivery

:::

::: {.column width="45%"}
![](Figures/postnl-bg.png)
:::
::::

# Prediction interval

::: {.emph}
A range of values $[\hat y_l, \hat y_u]$ that cover the true value $y$ of unseen cases with probability $1-\alpha$
:::


## Missing data complicates prediction

How to deal with observed predictors?

- Complete case analysis? No.
- Imputation: single (deterministic) or multiple (stochastic)?
  + __Single imputation:__ unbiased predictions [@little_regression_1992], but invalid uncertainty quantification [@van_buuren_flexible_2018; @zaffran_predictive_2024].
  + __Multiple imputation:__ valid for inference, but how to use for prediction uncertainty?


## Calculating prediction intervals

<br><br>

::::{.emph}
:::{.emph-header}
Prediction uncertainty^[Under standard linear regression assumptions, the prediction interval covers the true $y$ value with probability $1-\alpha$.]
:::

$U =$ Residual variance + model uncertainty
::::



## With missing data

Additional assumption: imputation model is appropriate

::::{.emph}
:::{.emph-header}
Prediction uncertainty with missing data^[Under standard linear regression assumptions, plus the assumption that the imputation model is appropriate, the prediction interval covers the true $y$ value with probability $1-\alpha$.]
:::

Residual variance + model uncertainty + imputation uncertainty^[Obtainable via Rubin's Rules [-@rubin_inference_1976]: $T = U + B(1 + 1/m)$, $U =$ residual variance + model uncertainty; $B(1+1/m) =$ imputation uncertainty.]
::::

## Evaluation (simulation)
::::{.columns}

:::{.column width = "40%"}
Linear regression model: $y = X\beta + \varepsilon$

---

$X \sim MVN(0, \Sigma)$

---

MAR missingness in __train__, __test__ or __both__

---

:::

:::{.column width="60%"}
![](Figures/pattern.png){width="120%"}
:::
::::

Varied __sample size__, __correlation__


## Marginal coverage results

![Marginal coverage (y-axis) for multiple and single imputation, depending on whether missingness occurs only in the training data, only in the test data, or in both, for different sizes of the training data.](Figures/marginal.png)

## Conditional coverage results

:::: {.columns}

::: {.column width="50%"}
::: {.fragment}
![Conditional coverage (y-axis) for multiple and single imputation, per number of missing observations per record.](Figures/main2.png){width=100%}
:::
:::

::: {.column width="50%"}
::: {.fragment}
![Conditional PI width (y-axis) for multiple and single imputation, per number of missing observations per record.](Figures/main3.png){width=100%}
:::
:::

::::

## {background-iframe="https://amices.org/mice/reference/predict_mi.html"}

#

:::{.emph}
__Multiple imputation produces prediction intervals that yield nominal coverage and scale with imputation uncertainty.__

- The approach is readily available in the `mice` package.

- Other (conformal) approaches [e.g., @zaffran_conformal_2023; @zaffran_predictive_2024] assume MCAR and require very large samples.

- More research is needed to test our method beyond linear regression.

:::



## References

::: {#refs}

:::


## Prediction interval calculation

Standard linear model prediction variance
$$
U = \hat \sigma^2 (1 + x^T (X^TX)^{-1} x)
$$
and prediction interval
$$
[\hat y - t_{\alpha/2, n-p}\sqrt U, \hat y + t_{\alpha/2, n-p}\sqrt U],
$$
based on a $t$-distribution with $n - p$ degrees of freedom.

## Prediction intervals with missing data

With missing data, the prediction variance equals
$$
T = \bar U + B(1 + 1/m),
$$
with $B = \text{var} [\hat y_j]$ over imputations $j = 1, \dots, m$. The prediction interval equals 
$$
[\bar {\hat y}_j - t_{\alpha/2, \nu}\sqrt T, \bar {\hat y}_j + t_{\alpha/2, \nu}\sqrt T],
$$
where $\bar {\hat y}_j = \sum_j \hat y_j$ and $\nu$ denotes the missing data degrees of freedom [@barnard_rubin_1999].